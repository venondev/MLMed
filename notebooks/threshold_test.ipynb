{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 76: A012\n",
      "1 / 76: A100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-7e2692099788>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0mlabel_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_fdata\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m     \u001B[0mraw_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mndi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzoom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_np\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m     \u001B[0mlabel_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mndi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzoom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabel_np\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0mlabel_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel_np\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlmed/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001B[0m in \u001B[0;36mzoom\u001B[0;34m(input, zoom, output, order, mode, cval, prefilter)\u001B[0m\n\u001B[1;32m    638\u001B[0m     \u001B[0mmode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_ni_support\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extend_mode_to_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mprefilter\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0morder\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 640\u001B[0;31m         \u001B[0mfiltered\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspline_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    641\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    642\u001B[0m         \u001B[0mfiltered\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlmed/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001B[0m in \u001B[0;36mspline_filter\u001B[0;34m(input, order, output, mode)\u001B[0m\n\u001B[1;32m    175\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0morder\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0maxis\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 177\u001B[0;31m             \u001B[0mspline_filter1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    178\u001B[0m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlmed/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001B[0m in \u001B[0;36mspline_filter1d\u001B[0;34m(input, order, axis, output, mode)\u001B[0m\n\u001B[1;32m    127\u001B[0m         \u001B[0mmode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_ni_support\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extend_mode_to_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m         \u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnormalize_axis_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 129\u001B[0;31m         \u001B[0m_nd_image\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspline_filter1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    130\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "files = filter(lambda x: x.endswith(\"_orig.nii.gz\"), files)\n",
    "files = list(map(lambda x: x.replace(\"_orig.nii.gz\", \"\"), files))\n",
    "sorted(files)\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "    raw = nib.load(os.path.join(datapath, name + \"_orig.nii.gz\"))\n",
    "    label = nib.load(os.path.join(datapath, name + \"_masks.nii.gz\"))\n",
    "\n",
    "    raw_np = raw.get_fdata()\n",
    "    label_np = label.get_fdata()\n",
    "\n",
    "    raw_np = ndi.zoom(raw_np, (0.5, 0.5, 0.5), order=3)\n",
    "    label_np = ndi.zoom(label_np, (0.5, 0.5, 0.5), order=0)\n",
    "    label_np = label_np > 0.5\n",
    "\n",
    "    perc = np.percentile(raw_np, 99)\n",
    "\n",
    "    t = (raw_np > perc).astype(int)\n",
    "\n",
    "    tt, num_labels = ndi.label(t)\n",
    "\n",
    "    t2, num_labels_mask = ndi.label(label_np)\n",
    "    for i in range(1, num_labels_mask+1):\n",
    "        volume = np.sum(t2 == i)\n",
    "        overlap = np.logical_and(t2 == i, t)\n",
    "        overlap_size = (np.logical_and(t2 == i, t)).sum()\n",
    "\n",
    "        x_idx, y_idx, z_idx = np.where(overlap)\n",
    "\n",
    "        idxx = len(x_idx) // 2\n",
    "        label = tt[x_idx[idxx], y_idx[idxx], z_idx[idxx]]\n",
    "\n",
    "        artery_volume = np.sum(tt == label)\n",
    "\n",
    "        volumes.append((overlap_size, artery_volume, volume))\n",
    "\n",
    "\n",
    "# t = ndi.binary_dilation(t, iterations=1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overlap_size</th>\n",
       "      <th>artery_volume</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>312.126437</td>\n",
       "      <td>8994.942529</td>\n",
       "      <td>352.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>646.625081</td>\n",
       "      <td>2615.956201</td>\n",
       "      <td>713.402952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2253.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>7632.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>9013.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>293.000000</td>\n",
       "      <td>10453.000000</td>\n",
       "      <td>328.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4595.000000</td>\n",
       "      <td>16783.000000</td>\n",
       "      <td>5006.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overlap_size  artery_volume       volume\n",
       "count     87.000000      87.000000    87.000000\n",
       "mean     312.126437    8994.942529   352.137931\n",
       "std      646.625081    2615.956201   713.402952\n",
       "min        9.000000    2253.000000    12.000000\n",
       "25%       48.500000    7632.000000    60.000000\n",
       "50%      105.000000    9013.000000   122.000000\n",
       "75%      293.000000   10453.000000   328.500000\n",
       "max     4595.000000   16783.000000  5006.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(volumes, columns=[\"overlap_size\", \"artery_volume\", \"volume\"])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A012', 'A100', 'A056', 'A123', 'A057', 'A029', 'A041', 'A098', 'A067', 'A076', 'A091_R', 'A038_R', 'A130_L', 'PA5', 'A135', 'A083', 'A059_L', 'A086', 'A082', 'A050', 'A097', 'A071', 'A105_R', 'A014', 'PA6', 'A001', 'A017_L', 'A133', 'A040', 'A003', 'A074', 'A044', 'A084', 'A085', 'A066', 'A126', 'A064', 'A043', 'A079', 'A015', 'A027', 'A028', 'A062_L', 'A081', 'A070', 'A087', 'A103', 'A121', 'A138', 'A008', 'A051_R', 'A096_L', 'A112', 'A095', 'A080', 'A092', 'A130_R', 'A038_M', 'A096_R', 'A010', 'A026', 'A134', 'A078_L', 'A032', 'A038_L', 'A060', 'A119', 'A113', 'A108', 'A024', 'A094_R', 'A105_L', 'A046', 'A093', 'A089_R', 'A077'] ['A045', 'A129', 'A114', 'A118', 'A073', 'A006', 'A136', 'A047', 'A049', 'A025', 'A019', 'A023_R', 'A120', 'A127', 'A042', 'A115', 'A088', 'A137', 'A072', 'A016', 'A009', 'A068', 'A059_R', 'A018', 'A013', 'A031', 'A124', 'A035', 'A078_R', 'A021', 'A005', 'A033', 'A054']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "### Split train test\n",
    "\n",
    "data_path = \"/media/lm/Samsung_T5/Uni/Medml/training\"\n",
    "\n",
    "train_split = 0.7\n",
    "# Load files\n",
    "files = os.listdir(data_path)\n",
    "files = filter(lambda x: x.endswith(\"_orig.nii.gz\"), files)\n",
    "files = list(map(lambda x: x.replace(\"_orig.nii.gz\", \"\"), files))\n",
    "np.random.shuffle(files)\n",
    "\n",
    "split = int(len(files) * train_split)\n",
    "train = files[:split]\n",
    "val = files[split:]\n",
    "\n",
    "print(train, val)\n",
    "\n",
    "def move(files_f, folder):\n",
    "    folder = os.path.join(data_path, folder)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    for i in files_f:\n",
    "        shutil.move(os.path.join(data_path, i + \"_orig.nii.gz\"), os.path.join(folder, i + \"_orig.nii.gz\"))\n",
    "        shutil.move(os.path.join(data_path, i + \"_masks.nii.gz\"), os.path.join(folder, i + \"_masks.nii.gz\"))\n",
    "\n",
    "move(train, \"train\")\n",
    "move(val, \"val\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "case = \"A003\"\n",
    "raw = nib.load(f\"/media/lm/Samsung_T5/Uni/Medml/training/train/{case}_orig.nii.gz\")\n",
    "label = nib.load(f\"/media/lm/Samsung_T5/Uni/Medml/training/train/{case}_masks.nii.gz\")\n",
    "\n",
    "raw_np = raw.get_fdata()\n",
    "label_np = label.get_fdata()\n",
    "\n",
    "raw_np = ndi.zoom(raw_np, (0.5, 0.5, 0.5), order=3)\n",
    "label_np = ndi.zoom(label_np, (0.5, 0.5, 0.5), order=0)\n",
    "label_np = label_np > 0.5\n",
    "\n",
    "perc = np.percentile(raw_np, 99)\n",
    "\n",
    "t = (raw_np > perc).astype(int)\n",
    "\n",
    "tt, num_labels = ndi.label(t)\n",
    "unique, counts = np.unique(tt, return_counts=True)\n",
    "\n",
    "t = ndi.binary_closing(t, iterations=1)\n",
    "\n",
    "keep_idx = unique[counts > 2000]\n",
    "keep = None\n",
    "for i in keep_idx:\n",
    "    if i == 0:\n",
    "        continue\n",
    "\n",
    "    if keep is None:\n",
    "        keep = tt == i\n",
    "    else:\n",
    "        keep = np.logical_or(keep, (tt == i))\n",
    "\n",
    "remove_idx = np.logical_not(keep)\n",
    "\n",
    "t[remove_idx] = 0\n",
    "\n",
    "idx = np.argmax(t.sum(axis=(1, 2)))\n",
    "print(idx)\n",
    "\n",
    "#t = ndi.gaussian_filter(t, sigma=0.1, order=0)\n",
    "# t = t > 0.5\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(t[idx])\n",
    "# plt.subplot(1, 2, 2)\n",
    "# t = ndi.gaussian_filter(t, sigma=0.15, order=0)\n",
    "# plt.imshow(t[idx])\n",
    "\n",
    "\n",
    "nib.save(nib.Nifti1Image(t.astype(int), raw.affine), \"./data/test_thres/art.nii.gz\")\n",
    "nib.save(nib.Nifti1Image(label_np.astype(int), raw.affine), \"./data/test_thres/mask.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "files = filter(lambda x: x.endswith(\"_orig.nii.gz\"), files)\n",
    "files = list(map(lambda x: x.replace(\"_orig.nii.gz\", \"\"), files))\n",
    "sorted(files)\n",
    "\n",
    "h5_save_folder = os.path.join(datapath, \"h5\")\n",
    "\n",
    "if not os.path.exists(h5_save_folder):\n",
    "    os.makedirs(h5_save_folder)\n",
    "\n",
    "# PARAMS\n",
    "zoom = False\n",
    "volume_threshold = 30000 #2000\n",
    "closing_thres = 3\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "    raw = nib.load(os.path.join(datapath, name + \"_orig.nii.gz\"))\n",
    "    label = nib.load(os.path.join(datapath, name + \"_masks.nii.gz\"))\n",
    "\n",
    "    raw_np = raw.get_fdata()\n",
    "    label_np = label.get_fdata()\n",
    "\n",
    "    if zoom:\n",
    "        raw_np = ndi.zoom(raw_np, (0.5, 0.5, 0.5), order=3)\n",
    "        label_np = ndi.zoom(label_np, (0.5, 0.5, 0.5), order=0)\n",
    "        label_np = label_np > 0.5\n",
    "\n",
    "    # find artery\n",
    "    perc = np.percentile(raw_np, 99)\n",
    "\n",
    "    t = (raw_np > perc).astype(int)\n",
    "\n",
    "    tt, num_labels = ndi.label(t)\n",
    "    unique, counts = np.unique(tt, return_counts=true)\n",
    "\n",
    "    keep_idx = unique[counts > volume_threshold]\n",
    "    keep = none\n",
    "    for i in keep_idx:\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        if keep is none:\n",
    "            keep = tt == i\n",
    "        else:\n",
    "            keep = np.logical_or(keep, (tt == i))\n",
    "\n",
    "    remove_idx = np.logical_not(keep)\n",
    "\n",
    "    t[remove_idx] = 0\n",
    "\n",
    "    t = ndi.binary_closing(t, iterations=closing_thres)\n",
    "\n",
    "    overlap_mask = np.logical_and(label_np, t)\n",
    "\n",
    "    # Normalize\n",
    "    min_val = raw_np.min()\n",
    "    max_val = raw_np.max()\n",
    "\n",
    "    raw_np = (raw_np - min_val) / (max_val - min_val)\n",
    "\n",
    "    with h5py.File(os.path.join(h5_save_folder, f\"{name}.h5\"), \"w\") as f:\n",
    "        f.create_dataset(\"raw\", data=raw_np)\n",
    "        f.create_dataset(\"label\", data=label_np)\n",
    "        f.create_dataset(\"artery\", data=t)\n",
    "        f.create_dataset(\"overlap_mask\", data=overlap_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import nibabel as nib\n",
    "outpath = \"./data/test_thres\"\n",
    "\n",
    "def h5_to_nii(p):\n",
    "    with h5py.File(p, \"r\") as f:\n",
    "        raw = f[\"raw\"][:]\n",
    "        mask = f[\"label\"][:]\n",
    "        artery = f[\"artery\"][:]\n",
    "        # overlap_mask = f[\"overlap_mask\"][:]\n",
    "\n",
    "        artery = ndi.binary_closing(artery, iterations=3)\n",
    "\n",
    "        nib.save(nib.Nifti1Image(raw, np.eye(4)), f\"{outpath}/raw.nii.gz\")\n",
    "        nib.save(nib.Nifti1Image(mask.astype(int), np.eye(4)), f\"{outpath}/mask.nii.gz\")\n",
    "        nib.save(nib.Nifti1Image(artery.astype(float), np.eye(4)), f\"{outpath}/artery.nii.gz\")\n",
    "        # nib.save(nib.Nifti1Image(overlap_mask.astype(int), np.eye(4)), f\"{outpath}/overlap_mask.nii.gz\")\n",
    "\n",
    "#h5_to_nii(\"/media/lm/Samsung_T5/Uni/Medml/training/train/h5/A001.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi\n",
    "import numpy as np\n",
    "# Calc stats\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train/h5_size_adjusted\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "sorted(files)\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    if not name.endswith(\".h5\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "    with h5py.File(os.path.join(datapath, name), \"r\") as f:\n",
    "        raw = f[\"raw\"][:]\n",
    "        mask = f[\"label\"][:]\n",
    "        artery = f[\"artery\"][:]\n",
    "\n",
    "        artery_labels, num_artery_labels = ndi.label(artery)\n",
    "\n",
    "        t2, num_labels_mask = ndi.label(mask)\n",
    "        for i in range(1, num_labels_mask+1):\n",
    "            # Volume and overlap\n",
    "            cur_mask = t2 == i\n",
    "            volume = np.sum(cur_mask)\n",
    "            overlap = np.logical_and(cur_mask, artery)\n",
    "            overlap_size = overlap.sum()\n",
    "\n",
    "            x_idx, y_idx, z_idx = np.where(overlap)\n",
    "\n",
    "            idxx = len(x_idx) // 2\n",
    "            label = artery_labels[x_idx[idxx], y_idx[idxx], z_idx[idxx]]\n",
    "\n",
    "            artery_volume = np.sum(artery_labels == label)\n",
    "\n",
    "            # Aneurysm start and pixel size\n",
    "\n",
    "            x_s = cur_mask.sum(axis=(1, 2))\n",
    "            y_s = cur_mask.sum(axis=(0, 2))\n",
    "            z_s = cur_mask.sum(axis=(0, 1))\n",
    "\n",
    "            x = np.where(x_s)[0][[0, -1]]\n",
    "            y = np.where(y_s)[0][[0, -1]]\n",
    "            z = np.where(z_s)[0][[0, -1]]\n",
    "\n",
    "            x_start, x_end = x[0], x[1]\n",
    "            y_start, y_end = y[0], y[1]\n",
    "            z_start, z_end = z[0], z[1]\n",
    "\n",
    "            x_size = x_end - x_start\n",
    "            y_size = y_end - y_start\n",
    "            z_size = z_end - z_start\n",
    "\n",
    "            volumes.append((name, overlap_size, artery_volume, volume, x_size, y_size, z_size, x_start, y_start, z_start, x_end, y_end, z_end))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(volumes, columns=[\"file\", \"overlap_size\", \"artery_volume\", \"volume\", \"x_size\", \"y_size\", \"z_size\", \"x_start\", \"y_start\", \"z_start\", \"x_end\", \"y_end\", \"z_end\"])\n",
    "df[\"overlap_to_volume_ratio\"] = df[\"overlap_size\"] / df[\"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"min_size\"] = df[[\"x_size\", \"y_size\", \"z_size\"]].min(axis=1)\n",
    "df[\"max_size\"] = df[[\"x_size\", \"y_size\", \"z_size\"]].max(axis=1)\n",
    "\n",
    "df[[\"file\", \"min_size\", \"max_size\"]].describe()\n",
    "\n",
    "\n",
    "# thres = 16\n",
    "# out = []\n",
    "# for index, row in df.iterrows():\n",
    "\n",
    "#     for fac in [1.5, 1.25, 1, 0.75, 0.5, 0.25]:\n",
    "#         if row[\"max_size\"] * fac < thres:\n",
    "#             out.append([row[\"file\"], row[\"min_size\"], row[\"max_size\"], fac, row[\"min_size\"] * fac, row[\"max_size\"] * fac])\n",
    "#             break\n",
    "\n",
    "# df2 = pd.DataFrame(out, columns=[\"file\", \"min_before\", \"max_before\", \"fac\", \"min_after\", \"max_after\"])\n",
    "# df2.sort_values(by='min_after', inplace=True)\n",
    "\n",
    "# df2.to_csv(\"./aneu_sizes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = df2.groupby('file')['fac'].apply(lambda x: list(np.unique(x)))\n",
    "t2 = df2.groupby('file')['fac'].apply(lambda x: len(list(x)))\n",
    "\n",
    "t[t2 >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Adjusted Sizes Dataset\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "import numpy as np\n",
    "# Calc stats\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/val/h5\"\n",
    "datapath_out = \"/media/lm/Samsung_T5/Uni/Medml/training/val/h5_size_adjusted\"\n",
    "thres = 16\n",
    "\n",
    "if not os.path.exists(datapath_out):\n",
    "    os.makedirs(datapath_out)\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "sorted(files)\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    if not name.endswith(\".h5\"):\n",
    "        continue\n",
    "\n",
    "\n",
    "    with h5py.File(os.path.join(datapath, name), \"r\") as f:\n",
    "        raw = f[\"raw\"][:]\n",
    "        mask = f[\"label\"][:]\n",
    "        artery = f[\"artery\"][:]\n",
    "        overlap_mask = f[\"overlap_mask\"][:]\n",
    "\n",
    "        fac_sizes = []\n",
    "        t2, num_labels_mask = ndi.label(mask)\n",
    "        for i in range(1, num_labels_mask + 1):\n",
    "            # Volume and overlap\n",
    "            cur_mask = t2 == i\n",
    "            x_s = cur_mask.sum(axis=(1, 2))\n",
    "            y_s = cur_mask.sum(axis=(0, 2))\n",
    "            z_s = cur_mask.sum(axis=(0, 1))\n",
    "\n",
    "            x = np.where(x_s)[0][[0, -1]]\n",
    "            y = np.where(y_s)[0][[0, -1]]\n",
    "            z = np.where(z_s)[0][[0, -1]]\n",
    "\n",
    "            x_start, x_end = x[0], x[1]\n",
    "            y_start, y_end = y[0], y[1]\n",
    "            z_start, z_end = z[0], z[1]\n",
    "\n",
    "            x_size = x_end - x_start\n",
    "            y_size = y_end - y_start\n",
    "            z_size = z_end - z_start\n",
    "\n",
    "            max_size = max(x_size, y_size, z_size)\n",
    "\n",
    "            for fac in [1.5, 1.25, 1, 0.75, 0.5, 0.3]:\n",
    "                if max_size * fac < thres:\n",
    "                    fac_sizes.append(fac)\n",
    "                    break\n",
    "        \n",
    "        fac_size = np.unique(fac_sizes)[0]\n",
    "        if len(np.unique(fac_sizes)) > 1:\n",
    "            print(f\"Different sizes: {np.unique(fac_sizes)}\")\n",
    "            fac_size = 1\n",
    "        \n",
    "\n",
    "        if fac_size != 1:\n",
    "            raw = ndi.zoom(raw, (fac_size, fac_size, fac_size), order=3)\n",
    "            mask = ndi.zoom(mask, (fac_size, fac_size, fac_size), order=0)\n",
    "            mask = mask > 0.5\n",
    "            artery = ndi.zoom(artery, (fac_size, fac_size, fac_size), order=0)\n",
    "            artery = artery > 0.5\n",
    "            overlap_mask = ndi.zoom(overlap_mask, (fac_size, fac_size, fac_size), order=0)\n",
    "            overlap_mask = overlap_mask > 0.5\n",
    "\n",
    "\n",
    "        # Normalize\n",
    "        min_val = raw.min()\n",
    "        max_val = raw.max()\n",
    "\n",
    "        raw_np = (raw - min_val) / (max_val - min_val)\n",
    "        \n",
    "\n",
    "        with h5py.File(os.path.join(datapath_out, name), \"w\") as f:\n",
    "            f.create_dataset(\"raw\", data=raw)\n",
    "            f.create_dataset(\"label\", data=mask)\n",
    "            f.create_dataset(\"artery\", data=artery)\n",
    "            f.create_dataset(\"overlap_mask\", data=overlap_mask)\n",
    "\n",
    "    print(f\"{idx} / {len(files)}: {name} {fac_size}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = {}\n",
    "\n",
    "test[(1,3, 4)] = 5\n",
    "(1,3, 4) in test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {}\n",
    "\n",
    "test[(1,3, 4)] = 5\n",
    "(1,3, 4) in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"/media/lm/Samsung_T5/Uni/Medml/training/train/h5/A001.h5\", \"r\") as f:\n",
    "    fac = 0.25\n",
    "    raw = f[\"raw\"][:]\n",
    "    mask = f[\"label\"][:]\n",
    "\n",
    "    raw = ndi.zoom(raw, (fac, fac, fac), order=3)\n",
    "    label = ndi.zoom(mask, (fac, fac, fac), order=0)\n",
    "    label_np = label > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fit mask to artery\n",
    "\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train/h5\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "sorted(files)\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    if not name.endswith(\".h5\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "    with h5py.File(os.path.join(datapath, name), \"r+\") as f:\n",
    "        raw = f[\"raw\"][:]\n",
    "        mask = f[\"label\"][:]\n",
    "        artery = f[\"artery\"][:]\n",
    "\n",
    "        artery = ndi.binary_closing(artery, iterations=3)\n",
    "\n",
    "        overlap_mask = np.logical_and(mask, artery)\n",
    "\n",
    "        f.create_dataset(\"overlap_mask\", data=overlap_mask)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "a = torch.tensor([5, 0.5])\n",
    "\n",
    "torch.maximum(torch.ones(a.shape), a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = np.zeros((20, 20, 20))\n",
    "\n",
    "\n",
    "test[4:8, 3:5, 2:7] = 1\n",
    "test[14:20, 8:14, 9:11] = 2\n",
    "\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "55983fb84f6e59716d1b915c21554dd223e7219f13cfb18971fe1502d0d0d902"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}