{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 76: A012\n",
      "1 / 76: A100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-7e2692099788>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0mlabel_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_fdata\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m     \u001B[0mraw_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mndi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzoom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_np\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m     \u001B[0mlabel_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mndi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzoom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabel_np\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0mlabel_np\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel_np\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlmed/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001B[0m in \u001B[0;36mzoom\u001B[0;34m(input, zoom, output, order, mode, cval, prefilter)\u001B[0m\n\u001B[1;32m    638\u001B[0m     \u001B[0mmode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_ni_support\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extend_mode_to_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    639\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mprefilter\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0morder\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 640\u001B[0;31m         \u001B[0mfiltered\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspline_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    641\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    642\u001B[0m         \u001B[0mfiltered\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlmed/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001B[0m in \u001B[0;36mspline_filter\u001B[0;34m(input, order, output, mode)\u001B[0m\n\u001B[1;32m    175\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0morder\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0maxis\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 177\u001B[0;31m             \u001B[0mspline_filter1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    178\u001B[0m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlmed/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\u001B[0m in \u001B[0;36mspline_filter1d\u001B[0;34m(input, order, axis, output, mode)\u001B[0m\n\u001B[1;32m    127\u001B[0m         \u001B[0mmode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_ni_support\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extend_mode_to_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m         \u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnormalize_axis_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 129\u001B[0;31m         \u001B[0m_nd_image\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspline_filter1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    130\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "files = filter(lambda x: x.endswith(\"_orig.nii.gz\"), files)\n",
    "files = list(map(lambda x: x.replace(\"_orig.nii.gz\", \"\"), files))\n",
    "sorted(files)\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "    raw = nib.load(os.path.join(datapath, name + \"_orig.nii.gz\"))\n",
    "    label = nib.load(os.path.join(datapath, name + \"_masks.nii.gz\"))\n",
    "\n",
    "    raw_np = raw.get_fdata()\n",
    "    label_np = label.get_fdata()\n",
    "\n",
    "    raw_np = ndi.zoom(raw_np, (0.5, 0.5, 0.5), order=3)\n",
    "    label_np = ndi.zoom(label_np, (0.5, 0.5, 0.5), order=0)\n",
    "    label_np = label_np > 0.5\n",
    "\n",
    "    perc = np.percentile(raw_np, 99)\n",
    "\n",
    "    t = (raw_np > perc).astype(int)\n",
    "\n",
    "    tt, num_labels = ndi.label(t)\n",
    "\n",
    "    t2, num_labels_mask = ndi.label(label_np)\n",
    "    for i in range(1, num_labels_mask+1):\n",
    "        volume = np.sum(t2 == i)\n",
    "        overlap = np.logical_and(t2 == i, t)\n",
    "        overlap_size = (np.logical_and(t2 == i, t)).sum()\n",
    "\n",
    "        x_idx, y_idx, z_idx = np.where(overlap)\n",
    "\n",
    "        idxx = len(x_idx) // 2\n",
    "        label = tt[x_idx[idxx], y_idx[idxx], z_idx[idxx]]\n",
    "\n",
    "        artery_volume = np.sum(tt == label)\n",
    "\n",
    "        volumes.append((overlap_size, artery_volume, volume))\n",
    "\n",
    "\n",
    "# t = ndi.binary_dilation(t, iterations=1).astype(int)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       overlap_size  artery_volume       volume\ncount     87.000000      87.000000    87.000000\nmean     312.126437    8994.942529   352.137931\nstd      646.625081    2615.956201   713.402952\nmin        9.000000    2253.000000    12.000000\n25%       48.500000    7632.000000    60.000000\n50%      105.000000    9013.000000   122.000000\n75%      293.000000   10453.000000   328.500000\nmax     4595.000000   16783.000000  5006.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overlap_size</th>\n      <th>artery_volume</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>312.126437</td>\n      <td>8994.942529</td>\n      <td>352.137931</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>646.625081</td>\n      <td>2615.956201</td>\n      <td>713.402952</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>9.000000</td>\n      <td>2253.000000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>48.500000</td>\n      <td>7632.000000</td>\n      <td>60.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>105.000000</td>\n      <td>9013.000000</td>\n      <td>122.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>293.000000</td>\n      <td>10453.000000</td>\n      <td>328.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4595.000000</td>\n      <td>16783.000000</td>\n      <td>5006.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(volumes, columns=[\"overlap_size\", \"artery_volume\", \"volume\"])\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A012', 'A100', 'A056', 'A123', 'A057', 'A029', 'A041', 'A098', 'A067', 'A076', 'A091_R', 'A038_R', 'A130_L', 'PA5', 'A135', 'A083', 'A059_L', 'A086', 'A082', 'A050', 'A097', 'A071', 'A105_R', 'A014', 'PA6', 'A001', 'A017_L', 'A133', 'A040', 'A003', 'A074', 'A044', 'A084', 'A085', 'A066', 'A126', 'A064', 'A043', 'A079', 'A015', 'A027', 'A028', 'A062_L', 'A081', 'A070', 'A087', 'A103', 'A121', 'A138', 'A008', 'A051_R', 'A096_L', 'A112', 'A095', 'A080', 'A092', 'A130_R', 'A038_M', 'A096_R', 'A010', 'A026', 'A134', 'A078_L', 'A032', 'A038_L', 'A060', 'A119', 'A113', 'A108', 'A024', 'A094_R', 'A105_L', 'A046', 'A093', 'A089_R', 'A077'] ['A045', 'A129', 'A114', 'A118', 'A073', 'A006', 'A136', 'A047', 'A049', 'A025', 'A019', 'A023_R', 'A120', 'A127', 'A042', 'A115', 'A088', 'A137', 'A072', 'A016', 'A009', 'A068', 'A059_R', 'A018', 'A013', 'A031', 'A124', 'A035', 'A078_R', 'A021', 'A005', 'A033', 'A054']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "### Split train test\n",
    "\n",
    "data_path = \"/media/lm/Samsung_T5/Uni/Medml/training\"\n",
    "\n",
    "train_split = 0.7\n",
    "# Load files\n",
    "files = os.listdir(data_path)\n",
    "files = filter(lambda x: x.endswith(\"_orig.nii.gz\"), files)\n",
    "files = list(map(lambda x: x.replace(\"_orig.nii.gz\", \"\"), files))\n",
    "np.random.shuffle(files)\n",
    "\n",
    "split = int(len(files) * train_split)\n",
    "train = files[:split]\n",
    "val = files[split:]\n",
    "\n",
    "print(train, val)\n",
    "\n",
    "def move(files_f, folder):\n",
    "    folder = os.path.join(data_path, folder)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    for i in files_f:\n",
    "        shutil.move(os.path.join(data_path, i + \"_orig.nii.gz\"), os.path.join(folder, i + \"_orig.nii.gz\"))\n",
    "        shutil.move(os.path.join(data_path, i + \"_masks.nii.gz\"), os.path.join(folder, i + \"_masks.nii.gz\"))\n",
    "\n",
    "move(train, \"train\")\n",
    "move(val, \"val\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "case = \"A003\"\n",
    "raw = nib.load(f\"/media/lm/Samsung_T5/Uni/Medml/training/train/{case}_orig.nii.gz\")\n",
    "label = nib.load(f\"/media/lm/Samsung_T5/Uni/Medml/training/train/{case}_masks.nii.gz\")\n",
    "\n",
    "raw_np = raw.get_fdata()\n",
    "label_np = label.get_fdata()\n",
    "\n",
    "raw_np = ndi.zoom(raw_np, (0.5, 0.5, 0.5), order=3)\n",
    "label_np = ndi.zoom(label_np, (0.5, 0.5, 0.5), order=0)\n",
    "label_np = label_np > 0.5\n",
    "\n",
    "perc = np.percentile(raw_np, 99)\n",
    "\n",
    "t = (raw_np > perc).astype(int)\n",
    "\n",
    "tt, num_labels = ndi.label(t)\n",
    "unique, counts = np.unique(tt, return_counts=True)\n",
    "\n",
    "t = ndi.binary_closing(t, iterations=1)\n",
    "\n",
    "keep_idx = unique[counts > 2000]\n",
    "keep = None\n",
    "for i in keep_idx:\n",
    "    if i == 0:\n",
    "        continue\n",
    "\n",
    "    if keep is None:\n",
    "        keep = tt == i\n",
    "    else:\n",
    "        keep = np.logical_or(keep, (tt == i))\n",
    "\n",
    "remove_idx = np.logical_not(keep)\n",
    "\n",
    "t[remove_idx] = 0\n",
    "\n",
    "idx = np.argmax(t.sum(axis=(1, 2)))\n",
    "print(idx)\n",
    "\n",
    "#t = ndi.gaussian_filter(t, sigma=0.1, order=0)\n",
    "# t = t > 0.5\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(t[idx])\n",
    "# plt.subplot(1, 2, 2)\n",
    "# t = ndi.gaussian_filter(t, sigma=0.15, order=0)\n",
    "# plt.imshow(t[idx])\n",
    "\n",
    "\n",
    "nib.save(nib.Nifti1Image(t.astype(int), raw.affine), \"./data/test_thres/art.nii.gz\")\n",
    "nib.save(nib.Nifti1Image(label_np.astype(int), raw.affine), \"./data/test_thres/mask.nii.gz\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 76: A012\n",
      "1 / 76: A100\n",
      "2 / 76: A056\n",
      "3 / 76: A123\n",
      "4 / 76: A057\n",
      "5 / 76: A029\n",
      "6 / 76: A041\n",
      "7 / 76: A098\n",
      "8 / 76: A067\n",
      "9 / 76: A076\n",
      "10 / 76: A091_R\n",
      "11 / 76: A038_R\n",
      "12 / 76: A130_L\n",
      "13 / 76: PA5\n",
      "14 / 76: A135\n",
      "15 / 76: A083\n",
      "16 / 76: A059_L\n",
      "17 / 76: A086\n",
      "18 / 76: A082\n",
      "19 / 76: A050\n",
      "20 / 76: A097\n",
      "21 / 76: A071\n",
      "22 / 76: A105_R\n",
      "23 / 76: A014\n",
      "24 / 76: PA6\n",
      "25 / 76: A001\n",
      "26 / 76: A017_L\n",
      "27 / 76: A133\n",
      "28 / 76: A040\n",
      "29 / 76: A003\n",
      "30 / 76: A074\n",
      "31 / 76: A044\n",
      "32 / 76: A084\n",
      "33 / 76: A085\n",
      "34 / 76: A066\n",
      "35 / 76: A126\n",
      "36 / 76: A064\n",
      "37 / 76: A043\n",
      "38 / 76: A079\n",
      "39 / 76: A015\n",
      "40 / 76: A027\n",
      "41 / 76: A028\n",
      "42 / 76: A062_L\n",
      "43 / 76: A081\n",
      "44 / 76: A070\n",
      "45 / 76: A087\n",
      "46 / 76: A103\n",
      "47 / 76: A121\n",
      "48 / 76: A138\n",
      "49 / 76: A008\n",
      "50 / 76: A051_R\n",
      "51 / 76: A096_L\n",
      "52 / 76: A112\n",
      "53 / 76: A095\n",
      "54 / 76: A080\n",
      "55 / 76: A092\n",
      "56 / 76: A130_R\n",
      "57 / 76: A038_M\n",
      "58 / 76: A096_R\n",
      "59 / 76: A010\n",
      "60 / 76: A026\n",
      "61 / 76: A134\n",
      "62 / 76: A078_L\n",
      "63 / 76: A032\n",
      "64 / 76: A038_L\n",
      "65 / 76: A060\n",
      "66 / 76: A119\n",
      "67 / 76: A113\n",
      "68 / 76: A108\n",
      "69 / 76: A024\n",
      "70 / 76: A094_R\n",
      "71 / 76: A105_L\n",
      "72 / 76: A046\n",
      "73 / 76: A093\n",
      "74 / 76: A089_R\n",
      "75 / 76: A077\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "files = filter(lambda x: x.endswith(\"_orig.nii.gz\"), files)\n",
    "files = list(map(lambda x: x.replace(\"_orig.nii.gz\", \"\"), files))\n",
    "sorted(files)\n",
    "\n",
    "h5_save_folder = os.path.join(datapath, \"h5\")\n",
    "\n",
    "if not os.path.exists(h5_save_folder):\n",
    "    os.makedirs(h5_save_folder)\n",
    "\n",
    "# PARAMS\n",
    "zoom = False\n",
    "volume_threshold = 30000 #2000\n",
    "closing_thres = 3\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "    raw = nib.load(os.path.join(datapath, name + \"_orig.nii.gz\"))\n",
    "    label = nib.load(os.path.join(datapath, name + \"_masks.nii.gz\"))\n",
    "\n",
    "    raw_np = raw.get_fdata()\n",
    "    label_np = label.get_fdata()\n",
    "\n",
    "    if zoom:\n",
    "        raw_np = ndi.zoom(raw_np, (0.5, 0.5, 0.5), order=3)\n",
    "        label_np = ndi.zoom(label_np, (0.5, 0.5, 0.5), order=0)\n",
    "        label_np = label_np > 0.5\n",
    "\n",
    "    # Find Artery\n",
    "    perc = np.percentile(raw_np, 99)\n",
    "\n",
    "    t = (raw_np > perc).astype(int)\n",
    "\n",
    "    tt, num_labels = ndi.label(t)\n",
    "    unique, counts = np.unique(tt, return_counts=True)\n",
    "\n",
    "    keep_idx = unique[counts > volume_threshold]\n",
    "    keep = None\n",
    "    for i in keep_idx:\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        if keep is None:\n",
    "            keep = tt == i\n",
    "        else:\n",
    "            keep = np.logical_or(keep, (tt == i))\n",
    "\n",
    "    remove_idx = np.logical_not(keep)\n",
    "\n",
    "    t[remove_idx] = 0\n",
    "\n",
    "    t = ndi.binary_closing(t, iterations=closing_thres)\n",
    "\n",
    "    overlap_mask = np.logical_and(label_np, t)\n",
    "\n",
    "    # Normalize\n",
    "    min_val = raw_np.min()\n",
    "    max_val = raw_np.max()\n",
    "\n",
    "    raw_np = (raw_np - min_val) / (max_val - min_val)\n",
    "\n",
    "    with h5py.File(os.path.join(h5_save_folder, f\"{name}.h5\"), \"w\") as f:\n",
    "        f.create_dataset(\"raw\", data=raw_np)\n",
    "        f.create_dataset(\"label\", data=label_np)\n",
    "        f.create_dataset(\"artery\", data=t)\n",
    "        f.create_dataset(\"overlap_mask\", data=overlap_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import nibabel as nib\n",
    "outpath = \"./data/test_thres\"\n",
    "\n",
    "def h5_to_nii(p):\n",
    "    with h5py.File(p, \"r\") as f:\n",
    "        raw = f[\"raw\"][:]\n",
    "        mask = f[\"label\"][:]\n",
    "        artery = f[\"artery\"][:]\n",
    "        # overlap_mask = f[\"overlap_mask\"][:]\n",
    "\n",
    "        artery = ndi.binary_closing(artery, iterations=3)\n",
    "\n",
    "        nib.save(nib.Nifti1Image(raw, np.eye(4)), f\"{outpath}/raw.nii.gz\")\n",
    "        nib.save(nib.Nifti1Image(mask.astype(int), np.eye(4)), f\"{outpath}/mask.nii.gz\")\n",
    "        nib.save(nib.Nifti1Image(artery.astype(float), np.eye(4)), f\"{outpath}/artery.nii.gz\")\n",
    "        # nib.save(nib.Nifti1Image(overlap_mask.astype(int), np.eye(4)), f\"{outpath}/overlap_mask.nii.gz\")\n",
    "\n",
    "h5_to_nii(\"/media/lm/Samsung_T5/Uni/Medml/training/train/h5/A001.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 78: A077.h5\n",
      "3 / 78: A089_R.h5\n",
      "4 / 78: A093.h5\n",
      "5 / 78: A046.h5\n",
      "6 / 78: A105_L.h5\n",
      "7 / 78: A094_R.h5\n",
      "8 / 78: A024.h5\n",
      "9 / 78: A108.h5\n",
      "10 / 78: A113.h5\n",
      "11 / 78: A119.h5\n",
      "12 / 78: A060.h5\n",
      "13 / 78: A038_L.h5\n",
      "14 / 78: A032.h5\n",
      "15 / 78: A078_L.h5\n",
      "16 / 78: A134.h5\n",
      "17 / 78: A026.h5\n",
      "18 / 78: A010.h5\n",
      "19 / 78: A096_R.h5\n",
      "20 / 78: A038_M.h5\n",
      "21 / 78: A130_R.h5\n",
      "22 / 78: A092.h5\n",
      "23 / 78: A080.h5\n",
      "24 / 78: A095.h5\n",
      "25 / 78: A112.h5\n",
      "26 / 78: A096_L.h5\n",
      "27 / 78: A051_R.h5\n",
      "28 / 78: A008.h5\n",
      "29 / 78: A138.h5\n",
      "30 / 78: A121.h5\n",
      "31 / 78: A103.h5\n",
      "32 / 78: A087.h5\n",
      "33 / 78: A070.h5\n",
      "34 / 78: A081.h5\n",
      "35 / 78: A062_L.h5\n",
      "36 / 78: A028.h5\n",
      "37 / 78: A027.h5\n",
      "38 / 78: A015.h5\n",
      "39 / 78: A079.h5\n",
      "40 / 78: A043.h5\n",
      "41 / 78: A064.h5\n",
      "42 / 78: A126.h5\n",
      "43 / 78: A066.h5\n",
      "44 / 78: A085.h5\n",
      "45 / 78: A084.h5\n",
      "46 / 78: A044.h5\n",
      "47 / 78: A074.h5\n",
      "48 / 78: A003.h5\n",
      "49 / 78: A040.h5\n",
      "50 / 78: A133.h5\n",
      "51 / 78: A017_L.h5\n",
      "52 / 78: PA6.h5\n",
      "53 / 78: A014.h5\n",
      "54 / 78: A012.h5\n",
      "55 / 78: A100.h5\n",
      "56 / 78: A056.h5\n",
      "57 / 78: A001.h5\n",
      "58 / 78: A123.h5\n",
      "59 / 78: A057.h5\n",
      "60 / 78: A029.h5\n",
      "61 / 78: A041.h5\n",
      "62 / 78: A098.h5\n",
      "63 / 78: A067.h5\n",
      "64 / 78: A076.h5\n",
      "65 / 78: A091_R.h5\n",
      "66 / 78: A038_R.h5\n",
      "67 / 78: A130_L.h5\n",
      "68 / 78: PA5.h5\n",
      "69 / 78: A135.h5\n",
      "70 / 78: A083.h5\n",
      "71 / 78: A059_L.h5\n",
      "72 / 78: A086.h5\n",
      "73 / 78: A082.h5\n",
      "74 / 78: A050.h5\n",
      "75 / 78: A097.h5\n",
      "76 / 78: A071.h5\n",
      "77 / 78: A105_R.h5\n"
     ]
    }
   ],
   "source": [
    "# Calc stats\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train/h5_zoomed\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "sorted(files)\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    if not name.endswith(\".h5\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "\n",
    "    with h5py.File(os.path.join(datapath, name), \"r\") as f:\n",
    "        raw = f[\"raw\"][:]\n",
    "        mask = f[\"label\"][:]\n",
    "        artery = f[\"artery\"][:]\n",
    "\n",
    "        artery_labels, num_artery_labels = ndi.label(artery)\n",
    "\n",
    "        t2, num_labels_mask = ndi.label(mask)\n",
    "        for i in range(1, num_labels_mask+1):\n",
    "            # Volume and overlap\n",
    "            cur_mask = t2 == i\n",
    "            volume = np.sum(cur_mask)\n",
    "            overlap = np.logical_and(cur_mask, artery)\n",
    "            overlap_size = overlap.sum()\n",
    "\n",
    "            x_idx, y_idx, z_idx = np.where(overlap)\n",
    "\n",
    "            idxx = len(x_idx) // 2\n",
    "            label = artery_labels[x_idx[idxx], y_idx[idxx], z_idx[idxx]]\n",
    "\n",
    "            artery_volume = np.sum(artery_labels == label)\n",
    "\n",
    "            # Aneurysm start and pixel size\n",
    "\n",
    "            x_s = cur_mask.sum(axis=(1, 2))\n",
    "            y_s = cur_mask.sum(axis=(0, 2))\n",
    "            z_s = cur_mask.sum(axis=(0, 1))\n",
    "\n",
    "            x = np.where(x_s)[0][[0, -1]]\n",
    "            y = np.where(y_s)[0][[0, -1]]\n",
    "            z = np.where(z_s)[0][[0, -1]]\n",
    "\n",
    "            x_start, x_end = x[0], x[1]\n",
    "            y_start, y_end = y[0], y[1]\n",
    "            z_start, z_end = z[0], z[1]\n",
    "\n",
    "            x_size = x_end - x_start\n",
    "            y_size = y_end - y_start\n",
    "            z_size = z_end - z_start\n",
    "\n",
    "            volumes.append((name, overlap_size, artery_volume, volume, x_size, y_size, z_size, x_start, y_start, z_start, x_end, y_end, z_end))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "       overlap_size  artery_volume       volume     x_size     y_size  \\\ncount     87.000000      87.000000    87.000000  87.000000  87.000000   \nmean     312.126437    8994.942529   352.137931   6.540230   6.482759   \nstd      646.625081    2615.956201   713.402952   3.747261   3.821184   \nmin        9.000000    2253.000000    12.000000   1.000000   2.000000   \n25%       48.500000    7632.000000    60.000000   4.000000   4.000000   \n50%      105.000000    9013.000000   122.000000   5.000000   6.000000   \n75%      293.000000   10453.000000   328.500000   8.500000   8.000000   \nmax     4595.000000   16783.000000  5006.000000  20.000000  20.000000   \n\n          z_size    x_start    y_start    z_start       x_end      y_end  \\\ncount  87.000000  87.000000  87.000000  87.000000   87.000000  87.000000   \nmean    6.701149  62.517241  45.609195  40.666667   69.057471  52.091954   \nstd     4.324390  16.299424  11.309963  12.803221   16.068427  11.926746   \nmin     1.000000  25.000000  14.000000  12.000000   29.000000  16.000000   \n25%     4.000000  52.000000  39.500000  33.000000   61.000000  46.000000   \n50%     6.000000  64.000000  44.000000  40.000000   69.000000  52.000000   \n75%     8.000000  71.000000  51.500000  48.000000   78.000000  58.000000   \nmax    26.000000  94.000000  84.000000  77.000000  100.000000  89.000000   \n\n           z_end  overlap_to_volume_ratio  \ncount  87.000000                87.000000  \nmean   47.367816                 0.870778  \nstd    12.422892                 0.076145  \nmin    21.000000                 0.641638  \n25%    40.000000                 0.822128  \n50%    46.000000                 0.883534  \n75%    54.000000                 0.920115  \nmax    80.000000                 1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overlap_size</th>\n      <th>artery_volume</th>\n      <th>volume</th>\n      <th>x_size</th>\n      <th>y_size</th>\n      <th>z_size</th>\n      <th>x_start</th>\n      <th>y_start</th>\n      <th>z_start</th>\n      <th>x_end</th>\n      <th>y_end</th>\n      <th>z_end</th>\n      <th>overlap_to_volume_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n      <td>87.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>312.126437</td>\n      <td>8994.942529</td>\n      <td>352.137931</td>\n      <td>6.540230</td>\n      <td>6.482759</td>\n      <td>6.701149</td>\n      <td>62.517241</td>\n      <td>45.609195</td>\n      <td>40.666667</td>\n      <td>69.057471</td>\n      <td>52.091954</td>\n      <td>47.367816</td>\n      <td>0.870778</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>646.625081</td>\n      <td>2615.956201</td>\n      <td>713.402952</td>\n      <td>3.747261</td>\n      <td>3.821184</td>\n      <td>4.324390</td>\n      <td>16.299424</td>\n      <td>11.309963</td>\n      <td>12.803221</td>\n      <td>16.068427</td>\n      <td>11.926746</td>\n      <td>12.422892</td>\n      <td>0.076145</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>9.000000</td>\n      <td>2253.000000</td>\n      <td>12.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>25.000000</td>\n      <td>14.000000</td>\n      <td>12.000000</td>\n      <td>29.000000</td>\n      <td>16.000000</td>\n      <td>21.000000</td>\n      <td>0.641638</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>48.500000</td>\n      <td>7632.000000</td>\n      <td>60.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>52.000000</td>\n      <td>39.500000</td>\n      <td>33.000000</td>\n      <td>61.000000</td>\n      <td>46.000000</td>\n      <td>40.000000</td>\n      <td>0.822128</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>105.000000</td>\n      <td>9013.000000</td>\n      <td>122.000000</td>\n      <td>5.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>64.000000</td>\n      <td>44.000000</td>\n      <td>40.000000</td>\n      <td>69.000000</td>\n      <td>52.000000</td>\n      <td>46.000000</td>\n      <td>0.883534</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>293.000000</td>\n      <td>10453.000000</td>\n      <td>328.500000</td>\n      <td>8.500000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>71.000000</td>\n      <td>51.500000</td>\n      <td>48.000000</td>\n      <td>78.000000</td>\n      <td>58.000000</td>\n      <td>54.000000</td>\n      <td>0.920115</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4595.000000</td>\n      <td>16783.000000</td>\n      <td>5006.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>26.000000</td>\n      <td>94.000000</td>\n      <td>84.000000</td>\n      <td>77.000000</td>\n      <td>100.000000</td>\n      <td>89.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(volumes, columns=[\"file\", \"overlap_size\", \"artery_volume\", \"volume\", \"x_size\", \"y_size\", \"z_size\", \"x_start\", \"y_start\", \"z_start\", \"x_end\", \"y_end\", \"z_end\"])\n",
    "df[\"overlap_to_volume_ratio\"] = df[\"overlap_size\"] / df[\"volume\"]\n",
    "\n",
    "# df = pd.read_csv(\"/media/lm/Samsung_T5/Uni/Medml/training/train/h5_zoomed/stats.csv\")\n",
    "\n",
    "df.describe()\n",
    "# df.sort_values(by=\"x_size\", ascending=True).head(10)\n",
    "\n",
    "# df.to_csv(\"/media/lm/Samsung_T5/Uni/Medml/training/train/h5_zoomed/stats.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 76: A077.h5\n",
      "1 / 76: A089_R.h5\n",
      "2 / 76: A093.h5\n",
      "3 / 76: A046.h5\n",
      "4 / 76: A105_L.h5\n",
      "5 / 76: A094_R.h5\n",
      "6 / 76: A024.h5\n",
      "7 / 76: A108.h5\n",
      "8 / 76: A113.h5\n",
      "9 / 76: A119.h5\n",
      "10 / 76: A060.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-b259fd896131>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mraw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"raw\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"label\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0martery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"artery\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0moverlap_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogical_and\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0martery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mh5py/_objects.pyx\u001B[0m in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mh5py/_objects.pyx\u001B[0m in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mlmed/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, args, new_dtype)\u001B[0m\n\u001B[1;32m    785\u001B[0m         \u001B[0mmspace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh5s\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_simple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mselection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    786\u001B[0m         \u001B[0mfspace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 787\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmspace\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfspace\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdxpl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dxpl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    788\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[0;31m# Patch up the output for NumPy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# fit mask to artery\n",
    "\n",
    "datapath = \"/media/lm/Samsung_T5/Uni/Medml/training/train/h5\"\n",
    "\n",
    "files = os.listdir(datapath)\n",
    "sorted(files)\n",
    "\n",
    "volumes = []\n",
    "for idx, name in enumerate(files):\n",
    "    if not name.endswith(\".h5\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"{idx} / {len(files)}: {name}\")\n",
    "\n",
    "    with h5py.File(os.path.join(datapath, name), \"r+\") as f:\n",
    "        raw = f[\"raw\"][:]\n",
    "        mask = f[\"label\"][:]\n",
    "        artery = f[\"artery\"][:]\n",
    "\n",
    "        artery = ndi.binary_closing(artery, iterations=3)\n",
    "\n",
    "        overlap_mask = np.logical_and(mask, artery)\n",
    "\n",
    "        f.create_dataset(\"overlap_mask\", data=overlap_mask)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}